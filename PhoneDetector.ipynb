{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da47c9cd-574e-46d4-bbce-9a0d876b1efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Detection Summary\n",
      "📱 Phones detected: 141\n",
      "🧍‍♂️ Background people detected: 1415\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "\n",
    "# Initialize models\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "yolo = YOLO(\"yolov8n.pt\")  # Replace with fine-tuned weights later\n",
    "\n",
    "# Counters\n",
    "phone_count = 0\n",
    "background_person_count = 0\n",
    "\n",
    "# Filter thresholds\n",
    "PHONE_ASPECT_RATIO_RANGE = (1.3, 2.5)  # Typical phone shape\n",
    "PHONE_MIN_AREA = 5000  # Minimum pixel area for phone detection\n",
    "\n",
    "def is_probable_phone(x1, y1, x2, y2):\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    aspect_ratio = h / w if w > 0 else 0\n",
    "    area = w * h\n",
    "    return (PHONE_ASPECT_RATIO_RANGE[0] <= aspect_ratio <= PHONE_ASPECT_RATIO_RANGE[1]) and (area >= PHONE_MIN_AREA)\n",
    "\n",
    "def draw_stop_button(frame):\n",
    "    btn_color = (0, 0, 255)\n",
    "    btn_pos = (frame.shape[1] - 120, 20)\n",
    "    btn_size = (100, 50)\n",
    "    cv2.rectangle(frame, btn_pos, (btn_pos[0]+btn_size[0], btn_pos[1]+btn_size[1]), btn_color, -1)\n",
    "    cv2.putText(frame, \"STOP\", (btn_pos[0]+10, btn_pos[1]+35),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    return btn_pos, btn_size\n",
    "\n",
    "def is_button_clicked(event, x, y, flags, param):\n",
    "    global stop_requested\n",
    "    bx, by, bw, bh = param\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if bx <= x <= bx + bw and by <= y <= by + bh:\n",
    "            stop_requested = True\n",
    "\n",
    "# Camera & window\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Detection\")\n",
    "stop_requested = False\n",
    "cv2.setMouseCallback(\"Detection\", is_button_clicked, param=(0, 0, 0, 0))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or stop_requested:\n",
    "        break\n",
    "\n",
    "    results = yolo.predict(source=frame, save=False, conf=0.5, verbose=False)\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            label = yolo.names[cls]\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            if label == \"cell phone\" and is_probable_phone(x1, y1, x2, y2):\n",
    "                phone_count += 1\n",
    "                color = (0, 0, 255)\n",
    "                cv2.putText(frame, \"PHONE\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            elif label == \"person\":\n",
    "                background_person_count += 1\n",
    "                color = (255, 255, 0)\n",
    "                cv2.putText(frame, \"PERSON\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "    btn_pos, btn_size = draw_stop_button(frame)\n",
    "    cv2.setMouseCallback(\"Detection\", is_button_clicked,\n",
    "                         param=(btn_pos[0], btn_pos[1], btn_size[0], btn_size[1]))\n",
    "\n",
    "    cv2.imshow(\"Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or stop_requested:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\n📊 Detection Summary\")\n",
    "print(f\"📱 Phones detected: {phone_count}\")\n",
    "print(f\"🧍‍♂️ Background people detected: {background_person_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ec5fe9-0015-4142-8139-a6f727dd3597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Category:\n",
      "1: phone\n",
      "2: not_phone\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Capturing images for category: 'not_phone'\n",
      "Press SPACE to capture, ESC to quit\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_0.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_1.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_2.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_3.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_4.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_5.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_6.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_7.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_8.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_9.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_10.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_11.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_12.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_13.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_14.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_15.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_16.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_17.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_18.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_19.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_20.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_21.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_22.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_23.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_24.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_25.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_26.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_27.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_28.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_29.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_30.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_31.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_32.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_33.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_34.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_35.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_36.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_37.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_38.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_39.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_40.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_41.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_42.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_43.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_44.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_45.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_46.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_47.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_48.jpg\n",
      "✅ Saved to Train: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\\not_phone\\not_phone_49.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_0.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_1.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_2.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_3.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_4.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_5.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_6.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_7.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_8.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_9.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_10.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_11.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_12.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_13.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_14.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_15.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_16.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_17.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_18.jpg\n",
      "✅ Saved to Validation: C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\\not_phone\\not_phone_19.jpg\n",
      "🎯 Collected enough images!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# 📂 Paths\n",
    "BASE_PATH = r\"C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\"\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, \"train\")\n",
    "VALID_PATH = os.path.join(BASE_PATH, \"validation\")\n",
    "CATEGORIES = [\"phone\", \"not_phone\"]\n",
    "\n",
    "# 🎯 Number of images\n",
    "TRAIN_COUNT = 50\n",
    "VALID_COUNT = 20\n",
    "\n",
    "# 🛠 Create folders if not exist\n",
    "for category in CATEGORIES:\n",
    "    os.makedirs(os.path.join(TRAIN_PATH, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(VALID_PATH, category), exist_ok=True)\n",
    "\n",
    "def capture_images(category):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"🚨 Error: Could not access the camera\")\n",
    "        return\n",
    "\n",
    "    print(f\"🎥 Capturing images for category: '{category}'\")\n",
    "    print(\"Press SPACE to capture, ESC to quit\")\n",
    "\n",
    "    count_train = 0\n",
    "    count_valid = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"🚨 Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Capture Dataset\", frame)\n",
    "\n",
    "        k = cv2.waitKey(1)\n",
    "        if k % 256 == 27:  # ESC pressed\n",
    "            print(\"❌ Exiting capture\")\n",
    "            break\n",
    "        elif k % 256 == 32:  # SPACE pressed\n",
    "            # Decide train or validation\n",
    "            if count_train < TRAIN_COUNT:\n",
    "                save_path = os.path.join(TRAIN_PATH, category, f\"{category}_{count_train}.jpg\")\n",
    "                count_train += 1\n",
    "                print(f\"✅ Saved to Train: {save_path}\")\n",
    "            elif count_valid < VALID_COUNT:\n",
    "                save_path = os.path.join(VALID_PATH, category, f\"{category}_{count_valid}.jpg\")\n",
    "                count_valid += 1\n",
    "                print(f\"✅ Saved to Validation: {save_path}\")\n",
    "            else:\n",
    "                print(\"🎯 Collected enough images!\")\n",
    "                break\n",
    "\n",
    "            cv2.imwrite(save_path, frame)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 🏃‍♂️ Main\n",
    "print(\"Select Category:\")\n",
    "print(\"1: phone\")\n",
    "print(\"2: not_phone\")\n",
    "choice = input(\"Enter 1 or 2: \")\n",
    "\n",
    "if choice == \"1\":\n",
    "    capture_images(\"phone\")\n",
    "elif choice == \"2\":\n",
    "    capture_images(\"not_phone\")\n",
    "else:\n",
    "    print(\"🚨 Invalid choice. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15d91acc-cb35-47a0-ab7a-9ee7cee98442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
      "4334752/4334752 [==============================] - 2s 0us/step\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 4s 188ms/step - loss: 0.7164 - accuracy: 0.4600 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 2s 140ms/step - loss: 0.7001 - accuracy: 0.3500 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.7023 - accuracy: 0.4200 - val_loss: 0.6973 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 2s 148ms/step - loss: 0.6993 - accuracy: 0.4800 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 2s 140ms/step - loss: 0.7155 - accuracy: 0.4000 - val_loss: 0.6964 - val_accuracy: 0.4250\n",
      "✅ Saved as models/phone_classifier.h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "TRAIN_DIR = r\"C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\train\"\n",
    "VAL_DIR = r\"C:\\Users\\sagni\\Downloads\\Exam Checker\\dataset\\validation\"\n",
    "\n",
    "# Data augmentation for training\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(224, 224), batch_size=8, class_mode='categorical'\n",
    ")\n",
    "val_data = val_gen.flow_from_directory(\n",
    "    VAL_DIR, target_size=(224, 224), batch_size=8, class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Build model\n",
    "base_model = MobileNetV3Small(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False  # Freeze base\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(2, activation='softmax')  # 2 classes: phone, not_phone\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(train_data, validation_data=val_data, epochs=5)\n",
    "\n",
    "# Save\n",
    "output_dir = r\"C:\\Users\\sagni\\Downloads\\Exam Checker\\models\"\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "model.save(os.path.join(output_dir, \"phone_classifier.h5\"))\n",
    "print(\"✅ Saved as models/phone_classifier.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e63dbf-8bdf-464f-bf06-a3d0c2331bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "yolo = YOLO(\"yolov8n.pt\")  # or yolov10n.pt\n",
    "print(yolo.names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1738bec-232a-4324-bcdd-ca43af9cc683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📡 Starting detection... Press ESC to quit.\n",
      "❌ Exiting...\n",
      "\n",
      "📊 Detection Summary\n",
      "📱 Phones detected: 1\n",
      "🧍‍♂️ People detected: 2875\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 📦 Load YOLO and MobileNetV3 models\n",
    "yolo = YOLO(\"yolov8n.pt\")  # Use YOLOv8 COCO weights (supports 'cell phone', 'person')\n",
    "classifier = load_model(r\"C:\\Users\\sagni\\Downloads\\Exam Checker\\models\\phone_classifier.h5\")\n",
    "\n",
    "# Class labels for MobileNetV3\n",
    "CLASS_LABELS = ['not_phone', 'phone']\n",
    "\n",
    "# Detection counters\n",
    "phone_count = 0\n",
    "person_count = 0\n",
    "\n",
    "def verify_phone(crop):\n",
    "    \"\"\"Use MobileNetV3 to verify if crop is actually a phone.\"\"\"\n",
    "    crop_resized = cv2.resize(crop, (224, 224))\n",
    "    crop_array = np.expand_dims(crop_resized, axis=0)\n",
    "    crop_array = preprocess_input(crop_array)\n",
    "    pred = classifier.predict(crop_array, verbose=0)\n",
    "    label_idx = np.argmax(pred)\n",
    "    confidence = pred[0][label_idx]\n",
    "    return CLASS_LABELS[label_idx], confidence\n",
    "\n",
    "# 🎥 Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"🚨 Error: Cannot access webcam\")\n",
    "    exit()\n",
    "\n",
    "print(\"📡 Starting detection... Press ESC to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"🚨 Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO detection (lower confidence threshold to 0.3)\n",
    "    results = yolo.predict(source=frame, save=False, conf=0.3, verbose=False)\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            label = yolo.names[cls]\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            color = (0, 255, 0)  # Default box color: green\n",
    "\n",
    "            if label in [\"cell phone\", \"mobile phone\"]:\n",
    "                # Pass crop to MobileNetV3 for verification\n",
    "                crop = frame[y1:y2, x1:x2]\n",
    "                verified_label, confidence = verify_phone(crop)\n",
    "                if verified_label == \"phone\" and confidence > 0.7:\n",
    "                    phone_count += 1\n",
    "                    color = (0, 0, 255)  # Red for phone\n",
    "                    label_text = f\"PHONE ({confidence:.2f})\"\n",
    "                else:\n",
    "                    label_text = f\"Not Phone ({confidence:.2f})\"\n",
    "\n",
    "            elif label == \"person\":\n",
    "                person_count += 1\n",
    "                color = (255, 255, 0)  # Cyan for person\n",
    "                label_text = \"PERSON\"\n",
    "\n",
    "            else:\n",
    "                # Draw other YOLO classes (for debugging)\n",
    "                label_text = label\n",
    "\n",
    "            # Draw box and label\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"Exam Monitoring\", frame)\n",
    "\n",
    "    # Exit on ESC\n",
    "    k = cv2.waitKey(1)\n",
    "    if k % 256 == 27:\n",
    "        print(\"❌ Exiting...\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 📊 Print detection summary\n",
    "print(\"\\n📊 Detection Summary\")\n",
    "print(f\"📱 Phones detected: {phone_count}\")\n",
    "print(f\"🧍‍♂️ People detected: {person_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f8031-0a58-4048-8d20-21565dd5df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49.7M/49.7M [02:06<00:00, 411kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📡 Starting detection... Press ESC to quit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "# 📦 Load YOLO (use medium or large weights for better accuracy)\n",
    "yolo = YOLO(\"yolov8m.pt\")  # or yolov8l.pt if you have good GPU\n",
    "\n",
    "# 📦 Load MobileNetV3 classifier\n",
    "mobilenet = load_model(r\"C:\\Users\\sagni\\Downloads\\Exam Checker\\models\\phone_classifier.h5\")\n",
    "\n",
    "# Labels\n",
    "CLASS_LABELS = ['not_phone', 'phone']\n",
    "\n",
    "# Counters\n",
    "phone_count = 0\n",
    "person_count = 0\n",
    "\n",
    "# 📌 Helper: Verify phone with MobileNetV3\n",
    "def verify_phone(crop):\n",
    "    try:\n",
    "        crop_resized = cv2.resize(crop, (224, 224))\n",
    "        crop_array = np.expand_dims(crop_resized, axis=0)\n",
    "        crop_array = preprocess_input(crop_array)\n",
    "        pred = mobilenet.predict(crop_array, verbose=0)\n",
    "        label_idx = np.argmax(pred)\n",
    "        confidence = pred[0][label_idx]\n",
    "        return CLASS_LABELS[label_idx], confidence\n",
    "    except:\n",
    "        return \"not_phone\", 0.0\n",
    "\n",
    "# 🎥 Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"🚨 Error: Cannot open webcam\")\n",
    "    exit()\n",
    "\n",
    "print(\"📡 Starting detection... Press ESC to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"🚨 Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO detection (conf threshold = 0.25)\n",
    "    results = yolo.predict(source=frame, save=False, conf=0.25, verbose=False)\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            yolo_label = yolo.names[cls_id]\n",
    "            confidence = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            color = (0, 255, 0)  # Default green box\n",
    "            label_text = f\"{yolo_label} ({confidence:.2f})\"\n",
    "\n",
    "            if yolo_label == \"cell phone\":\n",
    "                # If YOLO confidence < 0.5, verify with MobileNetV3\n",
    "                if confidence < 0.5:\n",
    "                    crop = frame[y1:y2, x1:x2]\n",
    "                    verified_label, verify_conf = verify_phone(crop)\n",
    "                    if verified_label == \"phone\" and verify_conf > 0.7:\n",
    "                        phone_count += 1\n",
    "                        color = (0, 0, 255)  # Red box for phone\n",
    "                        label_text = f\"PHONE ✔ ({verify_conf:.2f})\"\n",
    "                    else:\n",
    "                        label_text = f\"Not Phone ✖ ({verify_conf:.2f})\"\n",
    "                else:\n",
    "                    phone_count += 1\n",
    "                    color = (0, 0, 255)  # Red box for phone\n",
    "\n",
    "            elif yolo_label == \"person\":\n",
    "                person_count += 1\n",
    "                color = (255, 255, 0)  # Cyan box for person\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow(\"YOLO + MobileNetV3 Detection\", frame)\n",
    "\n",
    "    # Exit on ESC\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 📊 Summary\n",
    "print(\"\\n📊 Detection Summary:\")\n",
    "print(f\"📱 Phones detected: {phone_count}\")\n",
    "print(f\"🧍‍♂️ People detected: {person_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63679a2-4ee8-47e2-8ce2-cc830b9ae462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (FaceRecog)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
